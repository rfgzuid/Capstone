{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from bound_propagation import BoundModelFactory, HyperRectangle\n",
    "from bound_propagation.polynomial import Pow\n",
    "import torch\n",
    "\n",
    "class NNDM(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(NNDM, self).__init__(\n",
    "            nn.Linear(5, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = super().forward(x)\n",
    "        return out + x[:,:4]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, self.indices]\n",
    "    \n",
    "class HHead(nn.Sequential):\n",
    "    def __init__(self, x_0_max, x_2_max):\n",
    "        \n",
    "        super().__init__(\n",
    "            Pow(2),\n",
    "            nn.Linear(4, 2)\n",
    "        )\n",
    "        self[1].weight.data = torch.tensor([[-1/x_0_max**2, 0],\n",
    "                                            [0, 0],\n",
    "                                            [0, -1/x_2_max**2],\n",
    "                                            [0, 0]])\n",
    "        self[1].bias.data = torch.tensor([1., 1.])\n",
    "\n",
    "class CombinedModel(nn.Sequential):\n",
    "    def __init__(self, x_0_max, x_2_max):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.add_module('nndm', NNDM())\n",
    "        self.add_module('hhead', HHead(x_0_max, x_2_max))\n",
    "    \n",
    "# Parameters for safety function\n",
    "x_position = 2.4\n",
    "pole_angel = 0.2095  # In radians\n",
    "\n",
    "# thetanet = HThetaHead(pole_angel)\n",
    "net = CombinedModel(x_position, pole_angel)\n",
    "\n",
    "factory = BoundModelFactory()\n",
    "net = factory.build(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/Users/koentuin/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/bound_propagation/linear.py\", line 38, in ibp_forward_linear_jit\n    weight = weight.transpose(-1, -2).to(dtype)\n\n    w_mid = center.matmul(weight) + (bias.to(dtype).unsqueeze(-2) if bias is not None else torch.tensor(0.0, device=device, dtype=dtype))\n            ~~~~~~~~~~~~~ <--- HERE\n    w_diff = diff.matmul(weight.abs())\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (1x4 and 2x4)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m epsilon \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[1;32m      3\u001b[0m input_bounds \u001b[39m=\u001b[39m HyperRectangle\u001b[39m.\u001b[39mfrom_eps(x, epsilon)\n\u001b[0;32m----> 5\u001b[0m crown_bounds \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mcrown(input_bounds)\n\u001b[1;32m      6\u001b[0m crown_ibp_bounds \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mcrown_ibp(input_bounds)\n\u001b[1;32m      8\u001b[0m alpha_crown_bounds \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mcrown(input_bounds, alpha\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/bound_propagation/general.py:42\u001b[0m, in \u001b[0;36mBoundModule.crown\u001b[0;34m(self, region, bound_lower, bound_upper, alpha)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrown\u001b[39m(\u001b[39mself\u001b[39m, region, bound_lower\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bound_upper\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcrown_with_relaxation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcrown_relax, region, bound_lower, bound_upper, alpha)\n",
      "File \u001b[0;32m~/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/bound_propagation/general.py:50\u001b[0m, in \u001b[0;36mBoundModule.crown_with_relaxation\u001b[0;34m(self, relax, region, bound_lower, bound_upper, alpha)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrown_with_relaxation\u001b[39m(\u001b[39mself\u001b[39m, relax, region, bound_lower, bound_upper, alpha):\n\u001b[1;32m     48\u001b[0m     out_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate_size(region\u001b[39m.\u001b[39mlower\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 50\u001b[0m     relax(region)\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m alpha:\n\u001b[1;32m     53\u001b[0m         linear_bounds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha_crown(region, out_size, bound_lower, bound_upper)\n",
      "File \u001b[0;32m~/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/bound_propagation/general.py:28\u001b[0m, in \u001b[0;36mBoundModule.crown_relax\u001b[0;34m(self, region)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrown_relax\u001b[39m(\u001b[39mself\u001b[39m, region):\n\u001b[1;32m     25\u001b[0m     \u001b[39m# Force bounds based on IBP, which may be tighter. More importantly, this also works if say there\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# is a Clamp in front of a Log which requires x > 0, and a linear relaxation may violate this\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     interval_bounds \u001b[39m=\u001b[39m IntervalBounds(region, region\u001b[39m.\u001b[39mlower, region\u001b[39m.\u001b[39mupper)\n\u001b[0;32m---> 28\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mibp_forward(interval_bounds, save_input_bounds\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     30\u001b[0m     \u001b[39m# No grad for relaxations improves accuracy and stabilizes training for CROWN.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneed_relaxation:\n",
      "File \u001b[0;32m~/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/bound_propagation/sequential.py:38\u001b[0m, in \u001b[0;36mBoundSequential.ibp_forward\u001b[0;34m(self, bounds, save_relaxation, save_input_bounds)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mibp_forward\u001b[39m(\u001b[39mself\u001b[39m, bounds, save_relaxation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, save_input_bounds\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     37\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound_sequential:\n\u001b[0;32m---> 38\u001b[0m         bounds \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49mibp_forward(bounds, save_relaxation\u001b[39m=\u001b[39;49msave_relaxation, save_input_bounds\u001b[39m=\u001b[39;49msave_input_bounds)\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m bounds\n",
      "File \u001b[0;32m~/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/bound_propagation/sequential.py:38\u001b[0m, in \u001b[0;36mBoundSequential.ibp_forward\u001b[0;34m(self, bounds, save_relaxation, save_input_bounds)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mibp_forward\u001b[39m(\u001b[39mself\u001b[39m, bounds, save_relaxation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, save_input_bounds\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     37\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound_sequential:\n\u001b[0;32m---> 38\u001b[0m         bounds \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49mibp_forward(bounds, save_relaxation\u001b[39m=\u001b[39;49msave_relaxation, save_input_bounds\u001b[39m=\u001b[39;49msave_input_bounds)\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m bounds\n",
      "File \u001b[0;32m~/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/bound_propagation/activation.py:28\u001b[0m, in \u001b[0;36massert_bound_order.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     bounds \u001b[39m=\u001b[39m kwargs[keyword]\n\u001b[1;32m     25\u001b[0m \u001b[39massert\u001b[39;00m torch\u001b[39m.\u001b[39misnan(bounds\u001b[39m.\u001b[39mlower)\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misnan(bounds\u001b[39m.\u001b[39mupper)\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m \\\n\u001b[1;32m     26\u001b[0m        torch\u001b[39m.\u001b[39mall(bounds\u001b[39m.\u001b[39mlower \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m bounds\u001b[39m.\u001b[39mupper \u001b[39m+\u001b[39m \u001b[39m1e-6\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/bound_propagation/linear.py:74\u001b[0m, in \u001b[0;36mBoundLinear.ibp_forward\u001b[0;34m(self, bounds, save_relaxation, save_input_bounds)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m@assert_bound_order\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mibp_forward\u001b[39m(\u001b[39mself\u001b[39m, bounds, save_relaxation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, save_input_bounds\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     73\u001b[0m     center, diff \u001b[39m=\u001b[39m bounds\u001b[39m.\u001b[39mcenter, bounds\u001b[39m.\u001b[39mwidth \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m---> 74\u001b[0m     lower, upper \u001b[39m=\u001b[39m ibp_forward_linear_jit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule\u001b[39m.\u001b[39;49mbias, center, diff)\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m IntervalBounds(bounds\u001b[39m.\u001b[39mregion, lower, upper)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/Users/koentuin/Documents/Studie/Minor Engineering wit AI/CAI/venv/lib/python3.11/site-packages/bound_propagation/linear.py\", line 38, in ibp_forward_linear_jit\n    weight = weight.transpose(-1, -2).to(dtype)\n\n    w_mid = center.matmul(weight) + (bias.to(dtype).unsqueeze(-2) if bias is not None else torch.tensor(0.0, device=device, dtype=dtype))\n            ~~~~~~~~~~~~~ <--- HERE\n    w_diff = diff.matmul(weight.abs())\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (1x4 and 2x4)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 5)\n",
    "epsilon = 0.1\n",
    "input_bounds = HyperRectangle.from_eps(x, epsilon)\n",
    "\n",
    "crown_bounds = net.crown(input_bounds)\n",
    "crown_ibp_bounds = net.crown_ibp(input_bounds)\n",
    "\n",
    "alpha_crown_bounds = net.crown(input_bounds, alpha=True)\n",
    "alpha_crown_ibp_bounds = net.crown_ibp(input_bounds, alpha=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final lower bounds:  tensor([[ 0.1928,  0.1021,  0.0685, -0.1304]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final lower bounds: \", crown_bounds.lower[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounds(model, state, action_space_partition, epsilon):\n",
    "    \"\"\"\n",
    "    model: Pytorch neural network initialised with BoundModelFactory\n",
    "        - model input size: [state_dimensionality + action_dimensionality]\n",
    "        - model output size: [state_dimensionality]\n",
    "    state: Tensor with shape [state_dimensionality]\n",
    "    action_space_partition: Tensor with shape: [action_options] -> in future: [action_dimensionality, action_partition]\n",
    "    epsilon: Perturbation radius for input bounds\n",
    "    ---\n",
    "    output: [action_options, 2, state_dimensionality] (2: upperbound & lowerbound)\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for action in action_space_partition:\n",
    "        state_action = torch.cat((state, action.unsqueeze(0))).view(1, 5)\n",
    "        input_bounds = HyperRectangle.from_eps(state_action, epsilon)\n",
    "        crown_bounds = model.crown(input_bounds)\n",
    "\n",
    "        # Assuming the output dimension of the model is state_dimensionality\n",
    "        lower_bound = crown_bounds.lower[0].unsqueeze(0)\n",
    "        upper_bound = crown_bounds.upper[0].unsqueeze(0)\n",
    "\n",
    "        result.append(torch.cat((lower_bound, upper_bound), dim=0))\n",
    "\n",
    "    return torch.stack(result, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "carpole_data = np.load('Cartpole_data.npy')\n",
    "state = torch.Tensor(carpole_data[0, :4])\n",
    "action_space = torch.Tensor([0, 1])\n",
    "bounds_for_all_actions = get_bounds(net, state, action_space, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.0111,  0.0192, -0.0424,  0.0240,  0.0139],\n",
       "           [ 0.0099, -0.0062,  0.0128,  0.0017,  0.0328],\n",
       "           [ 0.0055, -0.0059,  0.0021,  0.0076,  0.0045],\n",
       "           [ 0.0070, -0.0147,  0.0137, -0.0156,  0.0235]]],\n",
       "\n",
       "\n",
       "         [[[ 0.0113,  0.0193, -0.0427,  0.0240,  0.0137],\n",
       "           [ 0.0100, -0.0063,  0.0127,  0.0017,  0.0328],\n",
       "           [ 0.0056, -0.0059,  0.0019,  0.0076,  0.0044],\n",
       "           [ 0.0071, -0.0146,  0.0136, -0.0157,  0.0232]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.0076,  0.0191, -0.0409,  0.0243,  0.0058],\n",
       "           [ 0.0100, -0.0047,  0.0090,  0.0013,  0.0301],\n",
       "           [ 0.0050, -0.0050,  0.0019,  0.0064,  0.0026],\n",
       "           [ 0.0083, -0.0126,  0.0114, -0.0144,  0.0244]]],\n",
       "\n",
       "\n",
       "         [[[ 0.0077,  0.0190, -0.0410,  0.0242,  0.0061],\n",
       "           [ 0.0101, -0.0049,  0.0089,  0.0013,  0.0303],\n",
       "           [ 0.0050, -0.0050,  0.0019,  0.0064,  0.0027],\n",
       "           [ 0.0084, -0.0128,  0.0114, -0.0146,  0.0247]]]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_action_index = 0\n",
    "\n",
    "guaranteed_next_state_set = bounds_for_all_actions[desired_action_index, :, :]\n",
    "guaranteed_next_state_set\n",
    "bounds_for_all_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n",
    "    \n",
    "dqn_model = DQN(4, 1)\n",
    "\n",
    "# TODO: when we have trained the model\n",
    "# dqn_model.load_state_dict(torch.load(PATH_TO_MODEL_WEIGHTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m state_action \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((state, torch\u001b[39m.\u001b[39mTensor(\u001b[39m1\u001b[39m)))\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[39m# Compute the safety function values\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m h_state_action \u001b[39m=\u001b[39m h(net(state_action))\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     32\u001b[0m h_state \u001b[39m=\u001b[39m h(state)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     34\u001b[0m \u001b[39m# Define the safety condition constraint\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# This is a simplified example assuming h(x) can be linearized or is linear\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m, in \u001b[0;36mh\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mh\u001b[39m(x):\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Example safety function\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m (torch\u001b[39m.\u001b[39mabs(x[\u001b[39m0\u001b[39m])\u001b[39m/\u001b[39mx_0_max \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mabs(x[\u001b[39m2\u001b[39;49m])\u001b[39m/\u001b[39mx_2_max)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "\"\"\"WORK IN PROGRESS\"\"\"\n",
    "\n",
    "import cvxpy as cp\n",
    "\n",
    "# Parameters for safety function\n",
    "x_0_max = 2.4\n",
    "x_2_max = 0.2095  # In radians\n",
    "\n",
    "# Define the safety function based on your system's requirements\n",
    "def h(x):\n",
    "    # Example safety function\n",
    "    return 1 - (torch.abs(x[0])/x_0_max + torch.abs(x[2])/x_2_max)\n",
    "\n",
    "# Define the optimization variable (control input)\n",
    "u = cp.Variable(1) # 1 because action is described by a single integer 0/1\n",
    "\n",
    "def knom(state_tensor):\n",
    "    with torch.no_grad():\n",
    "        q_values = dqn_model(state_tensor)\n",
    "        # Assuming you want the action with the highest Q-value\n",
    "        action = torch.argmax(q_values).item()\n",
    "        return action\n",
    "\n",
    "# Define the nominal control\n",
    "k_nom = knom(state)\n",
    "\n",
    "\n",
    "# Define the safety condition constraint\n",
    "alpha = 0.1  # Define alpha based on your requirements\n",
    "state_action = torch.cat((state, torch.Tensor(1))).view(1, 5)\n",
    "\n",
    "# Compute the safety function values\n",
    "h_state_action = h(net(state_action)).detach().numpy()\n",
    "h_state = h(state).detach().numpy()\n",
    "\n",
    "# Define the safety condition constraint\n",
    "# This is a simplified example assuming h(x) can be linearized or is linear\n",
    "safety_condition = cp.Constant(h_state_action) - alpha * cp.Constant(h_state) >= 0\n",
    "\n",
    "# Define constraints\n",
    "constraints = [safety_condition]  # Include other constraints if any\n",
    "\n",
    "# Define the objective function (minimizing deviation from nominal control)\n",
    "objective = cp.Minimize(cp.norm(u - k_nom, 2))\n",
    "\n",
    "# Define constraints\n",
    "constraints = [safety_condition]\n",
    "\n",
    "# Set up and solve the optimization problem\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve()\n",
    "\n",
    "# Optimal control input\n",
    "optimal_control_input = u.value if problem.status not in [\"infeasible\", \"unbounded\"] else None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a40ef642b076910db029035e8a6499a4c0b1b5d539d6340d12e574079074661"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
