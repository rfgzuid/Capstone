{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from bound_propagation import BoundModelFactory, HyperRectangle\n",
    "from bound_propagation.polynomial import Pow\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class NNDM(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(NNDM, self).__init__(\n",
    "            nn.Linear(28, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 24),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = super().forward(x)\n",
    "        return out + x[:,:24]\n",
    "\n",
    "    \n",
    "class HHead(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__(\n",
    "            Pow(2),\n",
    "            nn.Linear(24, 2)\n",
    "        )\n",
    "        # self[1].weight.data = torch.tensor([[-1/x_0_max**2, 0, 0, 0],\n",
    "        #                                     [0, 0, -1/x_2_max**2, 0]])\n",
    "        # self[1].bias.data = torch.tensor([1., 1.])\n",
    "\n",
    "class CombinedModel(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.add_module('nndm', NNDM())\n",
    "        self.add_module('hhead', HHead())\n",
    "    \n",
    "\n",
    "# thetanet = HThetaHead(pole_angel)\n",
    "net = CombinedModel()\n",
    "\n",
    "factory = BoundModelFactory()\n",
    "boundnet = factory.build(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(Actor, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = torch.tanh(self.layer3(x))\n",
    "        return self.layer3(x)\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, no_state_actions):\n",
    "        super(Critic, self).__init__()\n",
    "        self.layer1 = nn.Linear(no_state_actions, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, 1)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n",
    "    \n",
    "actor_network = Actor(24, 4)\n",
    "critic_network = Critic(28)\n",
    "\n",
    "# TODO: when we have trained the model\n",
    "# dqn_model.load_state_dict(torch.load(PATH_TO_MODEL_WEIGHTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 28)\n",
    "epsilon = 0.1\n",
    "input_bounds = HyperRectangle.from_eps(x, epsilon)\n",
    "\n",
    "crown_bounds = boundnet.crown(input_bounds)\n",
    "crown_ibp_bounds = boundnet.crown_ibp(input_bounds)\n",
    "\n",
    "alpha_crown_bounds = boundnet.crown(input_bounds, alpha=True)\n",
    "alpha_crown_ibp_bounds = boundnet.crown_ibp(input_bounds, alpha=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lower_bounds(model, state, action, epsilon):\n",
    "    \"\"\"\n",
    "    model: Pytorch neural network initialised with BoundModelFactory\n",
    "        - model input size: [state_dimensionality + action_dimensionality]\n",
    "        - model output size: [state_dimensionality]\n",
    "    state: Tensor with shape [state_dimensionality]\n",
    "    action: Tensor with the specified action partition\n",
    "    ---\n",
    "    output: [action_options, state_dimensionality] (2: upperbound & lowerbound)\n",
    "    \"\"\"\n",
    "\n",
    "    state_action = torch.cat((state, action), dim=1).view(1, -1)\n",
    "    input_bounds = HyperRectangle.from_eps(state_action, epsilon)\n",
    "    crown_bounds = model.crown(input_bounds)\n",
    "\n",
    "    lower_bound = crown_bounds.lower[0].unsqueeze(0)\n",
    "\n",
    "    return lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.6283e-02,  6.2691e-03, -1.4915e-02,  1.6204e-03,  1.2873e-02,\n",
       "           -8.1222e-03,  1.0502e-02, -4.8700e-03, -7.9150e-03, -1.9101e-02,\n",
       "            6.7544e-03,  1.5642e-03, -9.1911e-03,  9.4562e-05, -5.1320e-03,\n",
       "           -7.2536e-03, -1.3353e-02,  6.2870e-03,  3.2984e-03,  6.5543e-03,\n",
       "            4.6554e-03, -6.0388e-03,  3.1865e-03, -2.4600e-03,  1.9490e-02,\n",
       "           -9.5051e-03,  5.1683e-03, -3.0761e-03],\n",
       "          [ 5.4977e-03,  1.7959e-02,  1.6638e-02, -9.4214e-03, -5.3678e-03,\n",
       "            1.9432e-03, -1.7078e-02, -1.1867e-02,  1.7231e-02,  5.7204e-04,\n",
       "           -3.8280e-03,  4.7540e-03,  3.3574e-03,  6.9865e-03,  8.1688e-03,\n",
       "           -3.1000e-03,  2.9842e-03,  9.3601e-04,  2.2302e-03,  1.0668e-03,\n",
       "           -3.1726e-04, -4.5712e-03,  5.5388e-03, -3.6725e-04, -3.2278e-03,\n",
       "            8.2344e-03, -1.1634e-02,  1.2340e-02]]]],\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hfunction = HHead()\n",
    "state = torch.rand(1, 24)\n",
    "action = torch.rand(1, 4)\n",
    "lower_bounds = get_lower_bounds(boundnet, state, action, 0.1)\n",
    "lower_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfeasibilityError(Exception):\n",
    "    \"\"\"Exception raised if there are no actions that fulfill the safety criterions.\"\"\"\n",
    "\n",
    "    def __init__(self, message=\"No safe action to take\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WORK IN PROGRESS FOR BIPEDAL WALKER\"\"\"\n",
    "\n",
    "import cvxpy as cp\n",
    "\n",
    "def continuous_cbf(state, nominal_action, boundnet, hfunction, alpha, epsilon):\n",
    "    # Ensure nominal_action is a CVXPY parameter with the correct shape\n",
    "    nominal_action_cvx = cp.Parameter(nominal_action.shape[1])\n",
    "    nominal_action_cvx.value = nominal_action.view(-1).numpy()\n",
    "\n",
    "    # Define the optimization variable (control input)\n",
    "    action = cp.Variable(nominal_action.shape[1])\n",
    "\n",
    "    # Define the objective function\n",
    "    objective = cp.Minimize(cp.norm(action - nominal_action_cvx, 2))\n",
    "\n",
    "    # Obtain the linearized CBF coefficients\n",
    "    lower_bound_matrix = get_lower_bounds(boundnet, state, action, epsilon)\n",
    "\n",
    "    # Construct the linear CBF constraint using the coefficients\n",
    "    # Assuming the matrix is in the form [A, B] where A multiplies the state and B multiplies the action\n",
    "    A, B = torch.split(lower_bound_matrix, [state.size(1), action.size(0)], dim=1)\n",
    "    cbf_constraint = A @ state + B @ action >= alpha * hfunction(state)\n",
    "\n",
    "    # Add the CBF constraint to the problem\n",
    "    constraints = [cbf_constraint]\n",
    "\n",
    "    # Define and solve the optimization problem with the new constraint\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    return action.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_function(output_from_get_lower_bounds):\n",
    "    # Assuming output_from_get_lower_bounds is a 2D tensor where each row is a different bound\n",
    "    # We can take a simple operation like summing across the dimensions\n",
    "    # or any other operation that makes sense in your context\n",
    "    return torch.sum(output_from_get_lower_bounds, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 1 in argument 0, but got Variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m action \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[1;32m      4\u001b[0m lower_bounds \u001b[39m=\u001b[39m get_lower_bounds(boundnet, state, action, \u001b[39m0.1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m new_action \u001b[39m=\u001b[39m continuous_cbf(state, action, boundnet, h_function, \u001b[39m0.01\u001b[39;49m, \u001b[39m0.1\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[76], line 17\u001b[0m, in \u001b[0;36mcontinuous_cbf\u001b[0;34m(state, nominal_action, boundnet, hfunction, alpha, epsilon)\u001b[0m\n\u001b[1;32m     14\u001b[0m objective \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mMinimize(cp\u001b[39m.\u001b[39mnorm(cpaction \u001b[39m-\u001b[39m nominal_action_cvx, \u001b[39m2\u001b[39m))\n\u001b[1;32m     16\u001b[0m \u001b[39m# Obtain the linearized CBF coefficients\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m lower_bound_matrix \u001b[39m=\u001b[39m get_lower_bounds(boundnet, state, cpaction, epsilon)\n\u001b[1;32m     19\u001b[0m \u001b[39m# Construct the linear CBF constraint using the coefficients\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Assuming the matrix is in the form [A, B] where A multiplies the state and B multiplies the action\u001b[39;00m\n\u001b[1;32m     21\u001b[0m A, B \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msplit(lower_bound_matrix, [state\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), cpaction\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[74], line 12\u001b[0m, in \u001b[0;36mget_lower_bounds\u001b[0;34m(model, state, action, epsilon)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_lower_bounds\u001b[39m(model, state, action, epsilon):\n\u001b[1;32m      2\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    model: Pytorch neural network initialised with BoundModelFactory\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m        - model input size: [state_dimensionality + action_dimensionality]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m    output: [action_options, state_dimensionality] (2: upperbound & lowerbound)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     state_action \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((state, action), dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m     input_bounds \u001b[39m=\u001b[39m HyperRectangle\u001b[39m.\u001b[39mfrom_eps(state_action, epsilon)\n\u001b[1;32m     14\u001b[0m     crown_bounds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcrown(input_bounds)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 1 in argument 0, but got Variable"
     ]
    }
   ],
   "source": [
    "# hfunction = HHead()\n",
    "state = torch.rand(1, 24)\n",
    "action = torch.rand(1, 4)\n",
    "lower_bounds = get_lower_bounds(boundnet, state, action, 0.1)\n",
    "\n",
    "new_action = continuous_cbf(state, action, boundnet, h_function, 0.01, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_cbf(action_space, state, nominal_action, hfunction, h_nndm, alpha):\n",
    "    \"\"\"\n",
    "    action_space: A 1-dimensional tensor containing possible actions.\n",
    "    state: The current state of the system.\n",
    "    nominal_action: A pre-selected action by the nominal controller.\n",
    "    hfunction: A function representing the barrier condition.\n",
    "    h_nndm: A NNDM with the h function put on top.\n",
    "    alpha: A scaling factor.\n",
    "    \"\"\"\n",
    "    best_action = nominal_action\n",
    "    res = []\n",
    "    for action in action_space:\n",
    "        h = h_nndm(torch.cat((state, action.unsqueeze(0))).view(1, -1))\n",
    "        h_prev = hfunction(state)\n",
    "        if torch.all(torch.ge(h, alpha * h_prev)):\n",
    "            res += [(int(action!=nominal_action), h, action)]\n",
    "    best_action_tuple = min(res, key = lambda x: x[0])\n",
    "    \n",
    "    if sum(best_action_tuple[0] == action_tuple[0] for action_tuple in res) > 1:\n",
    "        best_action_tuple = min([action_tuple for action_tuple in res if action_tuple[0] == best_action_tuple[0]], key= lambda x: x[1])\n",
    "    best_action = best_action_tuple[2]\n",
    "    return best_action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a40ef642b076910db029035e8a6499a4c0b1b5d539d6340d12e574079074661"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
